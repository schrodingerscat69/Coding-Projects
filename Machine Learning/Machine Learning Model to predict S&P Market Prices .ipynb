{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8486b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      rownames  Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today  \\\n",
      "0            1  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270   \n",
      "1            2  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576   \n",
      "2            3  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514   \n",
      "3            4  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712   \n",
      "4            5  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178   \n",
      "...        ...   ...    ...    ...    ...    ...    ...       ...    ...   \n",
      "1084      1085  2010 -0.861  0.043 -2.173  3.599  0.015  3.205160  2.969   \n",
      "1085      1086  2010  2.969 -0.861  0.043 -2.173  3.599  4.242568  1.281   \n",
      "1086      1087  2010  1.281  2.969 -0.861  0.043 -2.173  4.835082  0.283   \n",
      "1087      1088  2010  0.283  1.281  2.969 -0.861  0.043  4.454044  1.034   \n",
      "1088      1089  2010  1.034  0.283  1.281  2.969 -0.861  2.707105  0.069   \n",
      "\n",
      "     Direction  \n",
      "0         Down  \n",
      "1         Down  \n",
      "2           Up  \n",
      "3           Up  \n",
      "4           Up  \n",
      "...        ...  \n",
      "1084        Up  \n",
      "1085        Up  \n",
      "1086        Up  \n",
      "1087        Up  \n",
      "1088        Up  \n",
      "\n",
      "[1089 rows x 10 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976\n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574\n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837\n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630\n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Copy the file path below\n",
    "data_file_path = \"\\\\Users\\\\HP\\\\Desktop\\\\MANN\\\\CODING\\\\PYTHON\\\\Weekly.csv\"\n",
    "\n",
    "\n",
    "# Read the file\n",
    "file_data = pd.read_csv(data_file_path)\n",
    "print(file_data)\n",
    "# Describes the each column of the file in 8 sections:\n",
    "##  Count: shows how many rows have non-missing values\n",
    "##  Mean: average of data\n",
    "##  Std: standard deviation, how numerically spread out the values are\n",
    "##  Min: lowest value\n",
    "##  Max: highest value\n",
    "## 25%, 50%, 75% (percentiles)\n",
    "file_data.describe()\n",
    "\n",
    "# Obtain a list of all columns in the dataset\n",
    "file_data.columns\n",
    "\n",
    "# dropna drops missing values in the column\n",
    "file_data = file_data.dropna(axis=0)\n",
    "\n",
    "# Select the predicting target (column) where Column in the name of the target\n",
    "y = file_data.Today\n",
    "\n",
    "# Choose features (columns that are later used to make predictions)\n",
    "data_features = ['Year',\"Lag1\",'Lag2','Lag3','Lag4','Lag5','Volume']\n",
    "X = file_data[data_features]\n",
    "\n",
    "# Review data used to make predictions\n",
    "X.describe()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10a5c5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following ---\n",
      "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume\n",
      "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976\n",
      "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574\n",
      "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837\n",
      "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630\n",
      "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728\n",
      "The predictions are:\n",
      "[-0.27  -2.576  3.514  0.712  1.178]\n"
     ]
    }
   ],
   "source": [
    "# Building your model\n",
    "\n",
    "# Use scikit-learn library to create models\n",
    "# Steps to building and using a model:\n",
    "## Define: what type of model is it? Other parameters of the model type are specified too\n",
    "## Fit: Capture patterns from provided data\n",
    "## Predict\n",
    "## Evaluate: determine accuracy of the model's predictions\n",
    "\n",
    "# Example of decision tree model with scikit-learn and feature being target variables\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "data_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit model\n",
    "data_model.fit(X,y)\n",
    "\n",
    "# Using the fitted model above, we can use it now to make predictions\n",
    "print(\"Making predictions for the following ---\")\n",
    "print(X.head())\n",
    "print(\"The predictions are:\")\n",
    "print(data_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a2eee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.261  -0.261   2.03    1.892   1.671   0.509   0.739  -0.461  -2.425\n",
      "   3.854  -1.002   1.207  -3.041  -0.869  -0.404  -1.393  -2.029  -2.496\n",
      "   1.789  -0.936   0.165   0.174  -1.089   0.238   0.748  -0.114  -0.748\n",
      "   2.05    1.458  -1.693  -0.155   0.123   1.458   1.458  -1.897  -1.875\n",
      "   2.26    1.36    0.6    -0.78    1.719   0.951   2.427  -0.342   0.34\n",
      "   3.085  10.707   0.528   0.773  -0.185  -0.061  -1.321  -0.8    -5.184\n",
      "   0.748  -3.897   4.195  -1.218   3.169  -1.81   -0.709   2.102   1.384\n",
      "  -2.76   -4.217  -4.034   0.6     1.499   0.555  -1.213   0.853   5.173\n",
      "  -2.496   3.75   -0.261  -0.637   2.48    0.555   1.147   0.72    1.499\n",
      "   0.971   0.555   0.65   -4.034   1.892   1.65   -0.061   1.171  -1.601\n",
      "   3.076   1.508   0.015  -3.898   0.159  -0.23   -1.348  -0.155   1.813\n",
      "  -0.062  -1.433   0.951   0.872   1.148   0.63   -2.349   0.958  -1.147\n",
      "   1.813  -0.897  -0.561  -2.451  -0.218   2.509   1.156   3.289   2.11\n",
      "  -0.557 -11.05   -0.255   0.872   1.112  -0.23   -0.7    -0.404   0.282\n",
      "  -2.149  -3.807   0.707   0.619   2.427   1.275  -5.412  -2.029  -0.266\n",
      "  -0.238  -1.117   3.269   2.106  -1.539  -4.226   4.15   -1.601   1.125\n",
      "   3.169   2.232   0.043  10.707   0.123  -4.277   0.608   3.076  -0.422\n",
      "  -0.83    1.156   0.798   2.312  10.707  -0.685   0.951  -5.412   2.05\n",
      "   0.999   1.813  -1.601  -0.533  -0.266  -1.798   2.566   0.555   5.771\n",
      "   1.692   0.127  -2.451  -0.858   0.049   1.167   1.665   3.75   -6.72\n",
      "   1.682  -0.218   1.207   1.735   0.987   0.627  -1.866  -0.402  -1.661\n",
      "  -2.958   0.54    0.049   1.334  -0.255   2.897  -0.346   4.314  -0.054\n",
      "  -5.634   1.892   1.245  -0.597   1.813   5.173  -1.727  -4.277   2.702\n",
      "  -0.253  -4.522   1.061  -1.606  -8.389   3.854   1.508   0.99    1.435\n",
      "   7.202  -1.661  -1.653   2.957   0.127   0.661   0.668   0.099   1.458\n",
      "   3.31    1.813   1.682   0.34   -2.569   1.37   -0.261   5.893  -4.226\n",
      "  -0.923   1.217  -8.389  -1.433   0.954   1.508  -1.693   0.063  -0.141\n",
      "  -1.711   0.576   2.11   -0.261   0.015   3.338   1.417   1.506   2.879\n",
      "  -2.029   2.225  -1.891   1.976  -2.471  -2.349   4.12  -11.05    1.849\n",
      "   0.971  -4.034  -2.471  -3.041  -1.81   -1.09   -0.393  -2.496   2.183\n",
      "   1.262   2.566   0.282]\n",
      "     Year   Lag1   Lag2    Lag3   Lag4   Lag5    Volume\n",
      "809  2005 -0.868  0.324  -0.629  0.041  0.469  1.721880\n",
      "597  2001 -0.397  2.107  -2.760 -0.079  0.905  1.221720\n",
      "278  1995 -0.858  1.692   0.859 -1.210  1.044  0.324650\n",
      "533  2000  1.247  5.748 -10.538  1.186 -1.891  1.007000\n",
      "482  1999  0.735 -1.597   2.870 -2.177  4.223  0.869660\n",
      "..    ...    ...    ...     ...    ...    ...       ...\n",
      "458  1998  3.361 -1.340   3.854  2.615  1.349  0.673098\n",
      "145  1992  0.999  1.161  -0.263  1.106  0.576  0.211304\n",
      "303  1995  1.168 -0.017   1.240  0.364  1.875  0.399926\n",
      "255  1995 -0.122  0.224   2.649 -1.399  0.223  0.241088\n",
      "500  1999 -0.411  0.665   0.872  0.673  2.106  0.772225\n",
      "\n",
      "[273 rows x 7 columns]\n",
      "2.6096703296703296\n"
     ]
    }
   ],
   "source": [
    "# Model Validation\n",
    "\n",
    "# Once you have a model, calculate the mean absolute error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_value = data_model.predict(X)\n",
    "mean_absolute_error(y, predicted_value)\n",
    "\n",
    "# Problem with 'In-Sample' Scores:\n",
    "## Data might not be accurate when model sees new data\n",
    "## To fix this, we can exclude some data from the model-building\n",
    "## process, and use those to test the model's accuracy on data it\n",
    "## hasn't seen before. This data is called validation data.\n",
    "\n",
    "# Use the train_test_split to break up the data into two pieces\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Numerical value to random_state argument guarantees we get the same split\n",
    "# every time we run the script\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X,y, random_state=0)\n",
    "\n",
    "# Define model\n",
    "data_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit model\n",
    "data_model.fit(train_X,train_y)\n",
    "\n",
    "# get predicted values on validation data\n",
    "val_predictions = data_model.predict(val_X)\n",
    "print(val_predictions)\n",
    "print(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "439d7e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  1\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  2\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  2\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  2\n",
      "Max leaf nodes: 10000  \t\t Mean Absolute Error:  2\n"
     ]
    }
   ],
   "source": [
    "# Underfitting and Overfitting\n",
    "\n",
    "# Overfitting: where a model matches the training data almost perfectly, but does poorly\n",
    "#              in validation and other new data.\n",
    "# Underfitting: when a model fails to capture distinctions and patterns in the data, so it \n",
    "#               performs poorly even in training data.\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    \n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5,50,500,5000,10000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "280b61b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9187684615384617\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "\n",
    "# The random forest uses many trees, and it makes a prediction by averaging the predictions of \n",
    "# each component tree. It generally has much better predictive accuracy than a single decision tree \n",
    "# and it works well with default parameters.\n",
    "\n",
    "# Build a random forest scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
